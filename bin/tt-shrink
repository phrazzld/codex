#!/bin/bash
# tt-shrink - Code size optimization using shared library

# Source the shared library
source "$(dirname "$0")/tt-common.sh"

tt_main() {
    # Configure this script
    tt_set_config \
        --template-name "shrink" \
        --output-file "SHRINK_BACKLOG_ITEMS.md" \
        --description "Analyzes codebase for size optimization opportunities"

    # Check for BACKLOG.md and create if missing
    if [[ ! -f "BACKLOG.md" ]]; then
        echo "Warning: BACKLOG.md not found. Creating empty backlog file..."
        echo "# BACKLOG" > BACKLOG.md
        echo "" >> BACKLOG.md
    fi

    # Read the current backlog content
    local backlog_content
    backlog_content=$(cat BACKLOG.md)

    # Set the template content
    tt_set_template << 'EOF'
# Code Size Optimization Backlog Items

You are an expert AI Code Optimization Specialist. Your goal is to analyze the provided codebase and generate actionable backlog items to significantly reduce its size while preserving all essential functionality.

## Objectives

- Dramatically reduce the overall size of the codebase
- Eliminate redundancy and duplication across files and modules
- Consolidate similar functionality into reusable, shared components
- Remove dead/unused code and unnecessary dependencies
- Simplify overly complex implementations
- Maintain or improve code readability despite reduction
- Ensure that 100% of the essential functionality is preserved

## Analysis Process

1. **Size Analysis:** Identify the largest files/modules and quantify current codebase size metrics (LOC by file/module/type, etc).

2. **Reduction Opportunities:** Catalog specific opportunities for size reduction:
   - Redundant/duplicated code across the codebase
   - Unused/dead code (functions, methods, imports, variables)
   - Unnecessarily verbose implementations
   - Overengineered abstractions that add complexity without value
   - Unnecessary dependencies that could be removed
   - Over-commented code where self-documenting approaches would be better

3. **Solution Analysis:** For each identified opportunity, consider:
   - The specific approach to reduce size
   - Potential size reduction (LOC, percentage)
   - Implementation complexity and risk
   - Verification strategy to ensure functionality remains intact

## Backlog Item Format

Format each optimization opportunity as a backlog item using this structure:

```markdown
- **[Size Optimization Task]**: Clear, actionable description of the optimization
  - **Complexity**: Simple/Medium/Complex
  - **Priority**: Critical/High/Medium/Low
  - **Rationale**: Specific reasons for this optimization
  - **Affected Areas**: Files, components, or patterns requiring changes
  - **Expected Outcome**: Amount of code reduction and other benefits
```

## Output Requirements

1. **Produce ONLY formatted backlog items** - no other commentary or analysis
2. **Group items by priority** level (Critical, High, Medium, Low)
3. **Ensure each item is:**
   - Specific and actionable (not vague)
   - Focused on one optimization opportunity
   - Realistic in scope (can be completed in 1-3 days of effort)
4. **Include a mix of:**
   - Quick wins (high impact, low effort)
   - Strategic improvements (may require more effort but provide significant reduction)
   - Architecture-level improvements where applicable
EOF

    # Set the context with backlog content
    tt_set_context "## Code Size Optimization Context

### Current Backlog
$backlog_content

### Request
Analyze the codebase and generate backlog items for code size optimization while preserving functionality.
Focus on reducing file sizes, eliminating duplicated code, and simplifying complex implementations."
}

# Main execution
tt_main "$@"
tt_run